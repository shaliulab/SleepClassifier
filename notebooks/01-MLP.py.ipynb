{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron (MLP) for binary classification\n",
    "\n",
    "A multilayer perceptron is a stack of fully connected (FC) layers\n",
    "Binary classification indicates the output lives in one dimension and is treated as a success event (Yes/No or ClassA/ClassB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path\n",
    "import time\n",
    "import logging\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vibflysleep/anaconda3/envs/TF/lib/python3.7/site-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
      "  warnings.warn(problem)\n"
     ]
    }
   ],
   "source": [
    "import sleepy.dataset\n",
    "import sleepy.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, loss, train_dataset, test_dataset, learning_rate=0.001, num_epochs=100):\n",
    "    \"\"\"\n",
    "    Run a experiment, defined by a model, a loss and a train and test set\n",
    "    \"\"\"\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "        loss=loss,\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    model.fit(train_dataset, epochs=num_epochs, validation_data=test_dataset)\n",
    "    print(\"Model training finished.\")\n",
    "    _, rmse = model.evaluate(train_dataset, verbose=0)\n",
    "    print(f\"Train RMSE: {round(rmse, 3)}\")\n",
    "\n",
    "    print(\"Evaluating model performance...\")\n",
    "    _, rmse = model.evaluate(test_dataset, verbose=0)\n",
    "    print(f\"Test RMSE: {round(rmse, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, metavar: str, test_vals: List):\n",
    "    \"\"\"\n",
    "    Custom split of data based on metavariables\n",
    "    \"\"\"\n",
    "    index_test = np.array([True if r in test_vals else False for r in data._adata.obs[\"Run\"]])\n",
    "    assert np.all(data._adata.obs.loc[index_test][\"Run\"].unique()[0] in test_vals)\n",
    "\n",
    "    index_train = ~index_test\n",
    "\n",
    "    labels  = data.get_labels(random=False)\n",
    "    labels_train = labels[index_train]\n",
    "    labels_test  = labels[index_test]\n",
    "\n",
    "    features  = data.get_features()\n",
    "    features_train = features[index_train, :]\n",
    "    features_test = features[index_test, :]\n",
    "\n",
    "\n",
    "    assert features_train.shape[0] == len(labels_train)\n",
    "    assert features_test.shape[0] == len(labels_test)\n",
    "\n",
    "    print(f\"{features_train.shape[0]} cells in training set\")\n",
    "    print(f\"{features_test.shape[0]} cells in test set\")\n",
    "\n",
    "\n",
    "    dataset_split = {\n",
    "        \"train\": (features_train, labels_train, index_train),\n",
    "        \"test\": (features_test, labels_test, index_test),\n",
    "\n",
    "    }\n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    snakemake\n",
    "    up = \"../..\"\n",
    "\n",
    "\n",
    "except NameError:\n",
    "    import json\n",
    "    class AttrDict(dict):\n",
    "        __getattr__ = dict.__getitem__\n",
    "        __setattr__ = dict.__setitem__\n",
    "\n",
    "    with open(\"01-MLP.json\", 'r') as fh:\n",
    "        snakemake = AttrDict(json.load(fh))\n",
    "        up = \"../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/1TB/Cloud/Lab/Projects/SleepSignature/workflow/results/20201224/scran/y_KCs/y_KCs_grouping-Condition.loom\n",
      "Treatment\n",
      "/1TB/Cloud/Lab/Projects/SleepSignature/sleep_classifier/results/y_KCs_Treatment\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "loomfile = snakemake.input[\"loomfile\"]\n",
    "model_name = snakemake.params[\"model\"]\n",
    "summary_csv = snakemake.output[\"summary_csv\"]\n",
    "test_str_txt = snakemake.output[\"test_str_txt\"]\n",
    "target = snakemake.params[\"target\"]\n",
    "random_labels = False#snakemake.params[\"random_labels\"]\n",
    "\n",
    "print(loomfile)\n",
    "print(target)\n",
    "print(model_name)\n",
    "print(random_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening /1TB/Cloud/Lab/Projects/SleepSignature/workflow/results/20201224/scran/y_KCs/y_KCs_grouping-Condition.loom\n",
      "Transposing loom dataset so rows become cells and columns become genes\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vibflysleep/anaconda3/envs/TF/lib/python3.7/site-packages/anndata/_core/anndata.py:119: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "data=sleepy.dataset.Dataset.from_loom(loomfile)\n",
    "data.set_target(target)\n",
    "assert data.get_features().shape[0] == len(data.get_labels())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Sleep = Code 0\n",
      "Label Wake = Code 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 'Sleep', 1: 'Wake'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.get_encoding([i for i in range(len(data._adata.obs[data._target].unique()))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define architecture (how many layers, with how many neurons, connectivity between neurons, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 classes\n"
     ]
    }
   ],
   "source": [
    "target=\"Treatment\"\n",
    "data.set_target(target)\n",
    "n_classes = len(data._adata.obs[target].unique())\n",
    "print(f\"{n_classes} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3893 cells in training set\n",
      "517 cells in test set\n"
     ]
    }
   ],
   "source": [
    "dataset_split = train_test_split(data, metavar = \"Treatment\", test_vals = [\"20200916\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"{random_labels}\")\n",
    "# dataset_split = data.train_test_split(random=random_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2954 cells\n",
    "1 epoch -> model has seen all cells once\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train architecture -> populate the neurons with weights that make sense i.e. correctly map the input (genes) to the output (wake/sleep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.sequential_model()\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(1000, activation='relu', kernel_initializer='he_normal', name=\"dense_1\", input_shape=(data.n_features,)))\n",
    "model1.add(Dense(n_classes, activation=\"softmax\", name=\"output\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1000)              9996000   \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 2002      \n",
      "=================================================================\n",
      "Total params: 9,998,002\n",
      "Trainable params: 9,998,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"../tensorboard\",\n",
    "    histogram_freq=0,  # How often to log histogram visualizations\n",
    "    embeddings_freq=0,  # How often to log embedding visualizations\n",
    "    update_freq=\"epoch\",\n",
    ")  # How often to write logs (default: once per epoch)\n",
    "\n",
    "callbacks=[\n",
    "    tb\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3893 samples, validate on 517 samples\n",
      "Epoch 1/150\n",
      "3893/3893 [==============================] - 1s 253us/sample - loss: 4.5719 - accuracy: 0.6116 - val_loss: 2.0748 - val_accuracy: 0.5996\n",
      "Epoch 2/150\n",
      "3893/3893 [==============================] - 1s 154us/sample - loss: 0.6076 - accuracy: 0.7580 - val_loss: 1.8216 - val_accuracy: 0.2766\n",
      "Epoch 3/150\n",
      "3893/3893 [==============================] - 1s 155us/sample - loss: 0.3253 - accuracy: 0.8672 - val_loss: 3.8474 - val_accuracy: 0.2360\n",
      "Epoch 4/150\n",
      "3893/3893 [==============================] - 1s 154us/sample - loss: 0.2290 - accuracy: 0.9116 - val_loss: 1.8111 - val_accuracy: 0.5706\n",
      "Epoch 5/150\n",
      "3893/3893 [==============================] - 1s 148us/sample - loss: 0.1862 - accuracy: 0.9306 - val_loss: 1.9570 - val_accuracy: 0.4275\n",
      "Epoch 6/150\n",
      "3893/3893 [==============================] - 1s 170us/sample - loss: 0.0914 - accuracy: 0.9792 - val_loss: 2.4002 - val_accuracy: 0.2785\n",
      "Epoch 7/150\n",
      "3893/3893 [==============================] - 1s 156us/sample - loss: 0.0772 - accuracy: 0.9812 - val_loss: 2.0554 - val_accuracy: 0.5513\n",
      "Epoch 8/150\n",
      "3893/3893 [==============================] - 1s 171us/sample - loss: 0.0598 - accuracy: 0.9861 - val_loss: 2.5483 - val_accuracy: 0.3133\n",
      "Epoch 9/150\n",
      "3893/3893 [==============================] - 1s 163us/sample - loss: 0.0221 - accuracy: 0.9995 - val_loss: 2.7316 - val_accuracy: 0.2921\n",
      "Epoch 10/150\n",
      "3893/3893 [==============================] - 1s 149us/sample - loss: 0.0133 - accuracy: 1.0000 - val_loss: 2.9526 - val_accuracy: 0.2940\n",
      "Epoch 11/150\n",
      "3893/3893 [==============================] - 1s 172us/sample - loss: 0.0097 - accuracy: 1.0000 - val_loss: 2.9164 - val_accuracy: 0.2901\n",
      "Epoch 12/150\n",
      "3893/3893 [==============================] - 1s 166us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 3.0904 - val_accuracy: 0.3346\n",
      "Epoch 13/150\n",
      "3893/3893 [==============================] - 1s 177us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 3.1836 - val_accuracy: 0.2921\n",
      "Epoch 14/150\n",
      "3893/3893 [==============================] - 1s 149us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.1809 - val_accuracy: 0.2921\n",
      "Epoch 15/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.4527 - val_accuracy: 0.3095\n",
      "Epoch 16/150\n",
      "3893/3893 [==============================] - 1s 154us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.8078 - val_accuracy: 0.3095\n",
      "Epoch 17/150\n",
      "3893/3893 [==============================] - 1s 146us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.9182 - val_accuracy: 0.3153\n",
      "Epoch 18/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 0.0032 - accuracy: 0.9995 - val_loss: 5.5362 - val_accuracy: 0.2398\n",
      "Epoch 19/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 0.8601 - accuracy: 0.8258 - val_loss: 1.6886 - val_accuracy: 0.5068\n",
      "Epoch 20/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 0.1092 - accuracy: 0.9625 - val_loss: 2.6050 - val_accuracy: 0.2650\n",
      "Epoch 21/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 0.0365 - accuracy: 0.9967 - val_loss: 2.9412 - val_accuracy: 0.2766\n",
      "Epoch 22/150\n",
      "3893/3893 [==============================] - 1s 152us/sample - loss: 0.0166 - accuracy: 0.9995 - val_loss: 3.2518 - val_accuracy: 0.2747\n",
      "Epoch 23/150\n",
      "3893/3893 [==============================] - 1s 152us/sample - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.9373 - val_accuracy: 0.3714\n",
      "Epoch 24/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 0.0069 - accuracy: 1.0000 - val_loss: 3.2103 - val_accuracy: 0.3424\n",
      "Epoch 25/150\n",
      "3893/3893 [==============================] - 1s 148us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.5076 - val_accuracy: 0.2979\n",
      "Epoch 26/150\n",
      "3893/3893 [==============================] - 1s 173us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.4734 - val_accuracy: 0.3114\n",
      "Epoch 27/150\n",
      "3893/3893 [==============================] - 1s 175us/sample - loss: 0.3111 - accuracy: 0.9458 - val_loss: 7.1682 - val_accuracy: 0.2418\n",
      "Epoch 28/150\n",
      "3893/3893 [==============================] - 1s 170us/sample - loss: 0.1542 - accuracy: 0.9648 - val_loss: 2.4178 - val_accuracy: 0.2863\n",
      "Epoch 29/150\n",
      "3893/3893 [==============================] - 1s 161us/sample - loss: 0.0422 - accuracy: 0.9936 - val_loss: 3.0695 - val_accuracy: 0.3095\n",
      "Epoch 30/150\n",
      "3893/3893 [==============================] - 1s 151us/sample - loss: 0.0959 - accuracy: 0.9710 - val_loss: 3.1721 - val_accuracy: 0.2843\n",
      "Epoch 31/150\n",
      "3893/3893 [==============================] - 1s 175us/sample - loss: 0.0148 - accuracy: 0.9987 - val_loss: 3.5415 - val_accuracy: 0.2805\n",
      "Epoch 32/150\n",
      "3893/3893 [==============================] - 1s 175us/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 4.0970 - val_accuracy: 0.3075\n",
      "Epoch 33/150\n",
      "3893/3893 [==============================] - 1s 160us/sample - loss: 0.0052 - accuracy: 0.9997 - val_loss: 3.6008 - val_accuracy: 0.2998\n",
      "Epoch 34/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.5713 - val_accuracy: 0.3288\n",
      "Epoch 35/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.9396 - val_accuracy: 0.2979\n",
      "Epoch 36/150\n",
      "3893/3893 [==============================] - 1s 154us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.9574 - val_accuracy: 0.3095\n",
      "Epoch 37/150\n",
      "3893/3893 [==============================] - 1s 152us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.0247 - val_accuracy: 0.3095\n",
      "Epoch 38/150\n",
      "3893/3893 [==============================] - 1s 150us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.1571 - val_accuracy: 0.3037\n",
      "Epoch 39/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.2481 - val_accuracy: 0.3095\n",
      "Epoch 40/150\n",
      "3893/3893 [==============================] - 1s 154us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.3119 - val_accuracy: 0.3095\n",
      "Epoch 41/150\n",
      "3893/3893 [==============================] - 1s 155us/sample - loss: 8.7421e-04 - accuracy: 1.0000 - val_loss: 4.5627 - val_accuracy: 0.2940\n",
      "Epoch 42/150\n",
      "3893/3893 [==============================] - 1s 154us/sample - loss: 7.0446e-04 - accuracy: 1.0000 - val_loss: 4.4729 - val_accuracy: 0.3211\n",
      "Epoch 43/150\n",
      "3893/3893 [==============================] - 1s 151us/sample - loss: 5.5814e-04 - accuracy: 1.0000 - val_loss: 4.7325 - val_accuracy: 0.2901\n",
      "Epoch 44/150\n",
      "3893/3893 [==============================] - 1s 152us/sample - loss: 4.4664e-04 - accuracy: 1.0000 - val_loss: 4.7215 - val_accuracy: 0.3153\n",
      "Epoch 45/150\n",
      "3893/3893 [==============================] - 1s 167us/sample - loss: 3.5975e-04 - accuracy: 1.0000 - val_loss: 5.0655 - val_accuracy: 0.2998\n",
      "Epoch 46/150\n",
      "3893/3893 [==============================] - 1s 163us/sample - loss: 2.9813e-04 - accuracy: 1.0000 - val_loss: 4.9935 - val_accuracy: 0.2998\n",
      "Epoch 47/150\n",
      "3893/3893 [==============================] - 1s 157us/sample - loss: 2.4937e-04 - accuracy: 1.0000 - val_loss: 4.9629 - val_accuracy: 0.3230\n",
      "Epoch 48/150\n",
      "3893/3893 [==============================] - 1s 175us/sample - loss: 3.8600e-04 - accuracy: 1.0000 - val_loss: 4.8149 - val_accuracy: 0.2882\n",
      "Epoch 49/150\n",
      "3893/3893 [==============================] - 1s 169us/sample - loss: 4.8604e-04 - accuracy: 1.0000 - val_loss: 4.9810 - val_accuracy: 0.3075\n",
      "Epoch 50/150\n",
      "3893/3893 [==============================] - 1s 172us/sample - loss: 3.0791e-04 - accuracy: 1.0000 - val_loss: 4.8782 - val_accuracy: 0.3153\n",
      "Epoch 51/150\n",
      "3893/3893 [==============================] - 1s 167us/sample - loss: 2.0713e-04 - accuracy: 1.0000 - val_loss: 5.2045 - val_accuracy: 0.3327\n",
      "Epoch 52/150\n",
      "3893/3893 [==============================] - 1s 167us/sample - loss: 1.4514e-04 - accuracy: 1.0000 - val_loss: 5.2884 - val_accuracy: 0.3211\n",
      "Epoch 53/150\n",
      "3893/3893 [==============================] - 1s 150us/sample - loss: 1.1598e-04 - accuracy: 1.0000 - val_loss: 5.3796 - val_accuracy: 0.3153\n",
      "Epoch 54/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 1.0050e-04 - accuracy: 1.0000 - val_loss: 5.3718 - val_accuracy: 0.3269\n",
      "Epoch 55/150\n",
      "3893/3893 [==============================] - 1s 154us/sample - loss: 8.8248e-05 - accuracy: 1.0000 - val_loss: 5.6533 - val_accuracy: 0.2979\n",
      "Epoch 56/150\n",
      "3893/3893 [==============================] - 1s 152us/sample - loss: 7.8317e-05 - accuracy: 1.0000 - val_loss: 5.5604 - val_accuracy: 0.3191\n",
      "Epoch 57/150\n",
      "3893/3893 [==============================] - 1s 150us/sample - loss: 6.8684e-05 - accuracy: 1.0000 - val_loss: 5.5671 - val_accuracy: 0.3269\n",
      "Epoch 58/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 6.1574e-05 - accuracy: 1.0000 - val_loss: 5.6410 - val_accuracy: 0.3250\n",
      "Epoch 59/150\n",
      "3893/3893 [==============================] - 1s 149us/sample - loss: 5.5232e-05 - accuracy: 1.0000 - val_loss: 5.5899 - val_accuracy: 0.3327\n",
      "Epoch 60/150\n",
      "3893/3893 [==============================] - 1s 150us/sample - loss: 4.9259e-05 - accuracy: 1.0000 - val_loss: 5.7509 - val_accuracy: 0.3211\n",
      "Epoch 61/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 4.4115e-05 - accuracy: 1.0000 - val_loss: 5.7763 - val_accuracy: 0.3250\n",
      "Epoch 62/150\n",
      "3893/3893 [==============================] - 1s 152us/sample - loss: 3.9486e-05 - accuracy: 1.0000 - val_loss: 5.8902 - val_accuracy: 0.3191\n",
      "Epoch 63/150\n",
      "3893/3893 [==============================] - 1s 150us/sample - loss: 3.5765e-05 - accuracy: 1.0000 - val_loss: 5.9098 - val_accuracy: 0.3250\n",
      "Epoch 64/150\n",
      "3893/3893 [==============================] - 1s 160us/sample - loss: 3.2781e-05 - accuracy: 1.0000 - val_loss: 6.0073 - val_accuracy: 0.3095\n",
      "Epoch 65/150\n",
      "3893/3893 [==============================] - 1s 168us/sample - loss: 2.9249e-05 - accuracy: 1.0000 - val_loss: 5.9652 - val_accuracy: 0.3288\n",
      "Epoch 66/150\n",
      "3893/3893 [==============================] - 1s 175us/sample - loss: 2.7274e-05 - accuracy: 1.0000 - val_loss: 5.9056 - val_accuracy: 0.3385\n",
      "Epoch 67/150\n",
      "3893/3893 [==============================] - 1s 175us/sample - loss: 2.3902e-05 - accuracy: 1.0000 - val_loss: 6.1265 - val_accuracy: 0.3153\n",
      "Epoch 68/150\n",
      "3893/3893 [==============================] - 1s 164us/sample - loss: 2.1999e-05 - accuracy: 1.0000 - val_loss: 6.0464 - val_accuracy: 0.3346\n",
      "Epoch 69/150\n",
      "3893/3893 [==============================] - 1s 167us/sample - loss: 2.0281e-05 - accuracy: 1.0000 - val_loss: 6.1759 - val_accuracy: 0.3191\n",
      "Epoch 70/150\n",
      "3893/3893 [==============================] - 1s 176us/sample - loss: 1.8126e-05 - accuracy: 1.0000 - val_loss: 6.2140 - val_accuracy: 0.3250\n",
      "Epoch 71/150\n",
      "3893/3893 [==============================] - 1s 171us/sample - loss: 1.6070e-05 - accuracy: 1.0000 - val_loss: 6.2420 - val_accuracy: 0.3269\n",
      "Epoch 72/150\n",
      "3893/3893 [==============================] - 1s 156us/sample - loss: 1.4405e-05 - accuracy: 1.0000 - val_loss: 6.3215 - val_accuracy: 0.3385\n",
      "Epoch 73/150\n",
      "3893/3893 [==============================] - 1s 151us/sample - loss: 0.8866 - accuracy: 0.8998 - val_loss: 1.6349 - val_accuracy: 0.2340\n",
      "Epoch 74/150\n",
      "3893/3893 [==============================] - 1s 154us/sample - loss: 0.3336 - accuracy: 0.8811 - val_loss: 1.5580 - val_accuracy: 0.5957\n",
      "Epoch 75/150\n",
      "3893/3893 [==============================] - 1s 152us/sample - loss: 0.1314 - accuracy: 0.9661 - val_loss: 1.6060 - val_accuracy: 0.3501\n",
      "Epoch 76/150\n",
      "3893/3893 [==============================] - 1s 149us/sample - loss: 0.0501 - accuracy: 0.9972 - val_loss: 1.8857 - val_accuracy: 0.3559\n",
      "Epoch 77/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 0.0317 - accuracy: 0.9987 - val_loss: 1.9601 - val_accuracy: 0.3694\n",
      "Epoch 78/150\n",
      "3893/3893 [==============================] - 1s 151us/sample - loss: 0.0203 - accuracy: 1.0000 - val_loss: 2.0270 - val_accuracy: 0.4023\n",
      "Epoch 79/150\n",
      "3893/3893 [==============================] - 1s 146us/sample - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.3616 - val_accuracy: 0.3443\n",
      "Epoch 80/150\n",
      "3893/3893 [==============================] - 1s 152us/sample - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.4536 - val_accuracy: 0.3424\n",
      "Epoch 81/150\n",
      "3893/3893 [==============================] - 1s 150us/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.5274 - val_accuracy: 0.3791\n",
      "Epoch 82/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.7389 - val_accuracy: 0.3172\n",
      "Epoch 83/150\n",
      "3893/3893 [==============================] - 1s 152us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.7516 - val_accuracy: 0.3230\n",
      "Epoch 84/150\n",
      "3893/3893 [==============================] - 1s 175us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.8110 - val_accuracy: 0.3327\n",
      "Epoch 85/150\n",
      "3893/3893 [==============================] - 1s 175us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.8959 - val_accuracy: 0.3191\n",
      "Epoch 86/150\n",
      "3893/3893 [==============================] - 1s 175us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.6955 - val_accuracy: 0.3791\n",
      "Epoch 87/150\n",
      "3893/3893 [==============================] - 1s 175us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9873 - val_accuracy: 0.3250\n",
      "Epoch 88/150\n",
      "3893/3893 [==============================] - 1s 172us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0098 - val_accuracy: 0.3327\n",
      "Epoch 89/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1136 - val_accuracy: 0.3288\n",
      "Epoch 90/150\n",
      "3893/3893 [==============================] - 1s 174us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.1804 - val_accuracy: 0.3308\n",
      "Epoch 91/150\n",
      "3893/3893 [==============================] - 1s 160us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.2088 - val_accuracy: 0.3308\n",
      "Epoch 92/150\n",
      "3893/3893 [==============================] - 1s 151us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.2788 - val_accuracy: 0.3308\n",
      "Epoch 93/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.3136 - val_accuracy: 0.3288\n",
      "Epoch 94/150\n",
      "3893/3893 [==============================] - 1s 152us/sample - loss: 9.9255e-04 - accuracy: 1.0000 - val_loss: 3.2814 - val_accuracy: 0.3540\n",
      "Epoch 95/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 8.8913e-04 - accuracy: 1.0000 - val_loss: 3.4185 - val_accuracy: 0.3346\n",
      "Epoch 96/150\n",
      "3893/3893 [==============================] - 1s 150us/sample - loss: 7.8747e-04 - accuracy: 1.0000 - val_loss: 3.5047 - val_accuracy: 0.3250\n",
      "Epoch 97/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 6.9961e-04 - accuracy: 1.0000 - val_loss: 3.5584 - val_accuracy: 0.3211\n",
      "Epoch 98/150\n",
      "3893/3893 [==============================] - 1s 152us/sample - loss: 6.2849e-04 - accuracy: 1.0000 - val_loss: 3.6003 - val_accuracy: 0.3230\n",
      "Epoch 99/150\n",
      "3893/3893 [==============================] - 1s 151us/sample - loss: 5.6638e-04 - accuracy: 1.0000 - val_loss: 3.5518 - val_accuracy: 0.3424\n",
      "Epoch 100/150\n",
      "3893/3893 [==============================] - 1s 151us/sample - loss: 5.0243e-04 - accuracy: 1.0000 - val_loss: 3.7270 - val_accuracy: 0.3153\n",
      "Epoch 101/150\n",
      "3893/3893 [==============================] - 1s 154us/sample - loss: 4.4793e-04 - accuracy: 1.0000 - val_loss: 3.6814 - val_accuracy: 0.3346\n",
      "Epoch 102/150\n",
      "3893/3893 [==============================] - 1s 151us/sample - loss: 3.9781e-04 - accuracy: 1.0000 - val_loss: 3.7980 - val_accuracy: 0.3211\n",
      "Epoch 103/150\n",
      "3893/3893 [==============================] - 1s 172us/sample - loss: 3.4943e-04 - accuracy: 1.0000 - val_loss: 3.8044 - val_accuracy: 0.3211\n",
      "Epoch 104/150\n",
      "3893/3893 [==============================] - 1s 176us/sample - loss: 3.0436e-04 - accuracy: 1.0000 - val_loss: 3.9433 - val_accuracy: 0.3211\n",
      "Epoch 105/150\n",
      "3893/3893 [==============================] - 1s 169us/sample - loss: 2.6239e-04 - accuracy: 1.0000 - val_loss: 3.9013 - val_accuracy: 0.3250\n",
      "Epoch 106/150\n",
      "3893/3893 [==============================] - 1s 175us/sample - loss: 2.3026e-04 - accuracy: 1.0000 - val_loss: 4.0097 - val_accuracy: 0.3366\n",
      "Epoch 107/150\n",
      "3893/3893 [==============================] - 1s 174us/sample - loss: 0.2109 - accuracy: 0.9563 - val_loss: 4.0273 - val_accuracy: 0.3153\n",
      "Epoch 108/150\n",
      "3893/3893 [==============================] - 1s 174us/sample - loss: 0.1078 - accuracy: 0.9735 - val_loss: 4.2581 - val_accuracy: 0.2882\n",
      "Epoch 109/150\n",
      "3893/3893 [==============================] - 1s 158us/sample - loss: 0.0176 - accuracy: 0.9959 - val_loss: 3.6325 - val_accuracy: 0.3346\n",
      "Epoch 110/150\n",
      "3893/3893 [==============================] - 1s 168us/sample - loss: 0.0021 - accuracy: 0.9997 - val_loss: 3.9471 - val_accuracy: 0.3056\n",
      "Epoch 111/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.6890 - val_accuracy: 0.3327\n",
      "Epoch 112/150\n",
      "3893/3893 [==============================] - 1s 147us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.7189 - val_accuracy: 0.3366\n",
      "Epoch 113/150\n",
      "3893/3893 [==============================] - 1s 152us/sample - loss: 9.9027e-04 - accuracy: 1.0000 - val_loss: 3.7715 - val_accuracy: 0.3366\n",
      "Epoch 114/150\n",
      "3893/3893 [==============================] - 1s 152us/sample - loss: 9.1869e-04 - accuracy: 1.0000 - val_loss: 3.7650 - val_accuracy: 0.3366\n",
      "Epoch 115/150\n",
      "3893/3893 [==============================] - 1s 151us/sample - loss: 8.5786e-04 - accuracy: 1.0000 - val_loss: 3.8410 - val_accuracy: 0.3308\n",
      "Epoch 116/150\n",
      "3893/3893 [==============================] - 1s 154us/sample - loss: 8.0477e-04 - accuracy: 1.0000 - val_loss: 3.8656 - val_accuracy: 0.3308\n",
      "Epoch 117/150\n",
      "3893/3893 [==============================] - 1s 149us/sample - loss: 7.5973e-04 - accuracy: 1.0000 - val_loss: 3.8866 - val_accuracy: 0.3308\n",
      "Epoch 118/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 7.1046e-04 - accuracy: 1.0000 - val_loss: 3.8561 - val_accuracy: 0.3366\n",
      "Epoch 119/150\n",
      "3893/3893 [==============================] - 1s 149us/sample - loss: 6.7176e-04 - accuracy: 1.0000 - val_loss: 3.9003 - val_accuracy: 0.3327\n",
      "Epoch 120/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 6.3626e-04 - accuracy: 1.0000 - val_loss: 3.8894 - val_accuracy: 0.3346\n",
      "Epoch 121/150\n",
      "3893/3893 [==============================] - 1s 154us/sample - loss: 6.0238e-04 - accuracy: 1.0000 - val_loss: 3.9599 - val_accuracy: 0.3308\n",
      "Epoch 122/150\n",
      "3893/3893 [==============================] - 1s 145us/sample - loss: 5.6606e-04 - accuracy: 1.0000 - val_loss: 3.9547 - val_accuracy: 0.3346\n",
      "Epoch 123/150\n",
      "3893/3893 [==============================] - 1s 167us/sample - loss: 5.3617e-04 - accuracy: 1.0000 - val_loss: 3.9902 - val_accuracy: 0.3308\n",
      "Epoch 124/150\n",
      "3893/3893 [==============================] - 1s 176us/sample - loss: 5.0525e-04 - accuracy: 1.0000 - val_loss: 4.0229 - val_accuracy: 0.3327\n",
      "Epoch 125/150\n",
      "3893/3893 [==============================] - 1s 175us/sample - loss: 4.7918e-04 - accuracy: 1.0000 - val_loss: 4.0309 - val_accuracy: 0.3308\n",
      "Epoch 126/150\n",
      "3893/3893 [==============================] - 1s 176us/sample - loss: 4.5378e-04 - accuracy: 1.0000 - val_loss: 4.0310 - val_accuracy: 0.3308\n",
      "Epoch 127/150\n",
      "3893/3893 [==============================] - 1s 170us/sample - loss: 4.2821e-04 - accuracy: 1.0000 - val_loss: 4.0924 - val_accuracy: 0.3269\n",
      "Epoch 128/150\n",
      "3893/3893 [==============================] - 1s 169us/sample - loss: 4.0486e-04 - accuracy: 1.0000 - val_loss: 4.1401 - val_accuracy: 0.3250\n",
      "Epoch 129/150\n",
      "3893/3893 [==============================] - 1s 169us/sample - loss: 3.8380e-04 - accuracy: 1.0000 - val_loss: 4.0914 - val_accuracy: 0.3269\n",
      "Epoch 130/150\n",
      "3893/3893 [==============================] - 1s 150us/sample - loss: 3.6350e-04 - accuracy: 1.0000 - val_loss: 4.1758 - val_accuracy: 0.3250\n",
      "Epoch 131/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 3.4244e-04 - accuracy: 1.0000 - val_loss: 4.1936 - val_accuracy: 0.3269\n",
      "Epoch 132/150\n",
      "3893/3893 [==============================] - 1s 150us/sample - loss: 3.2273e-04 - accuracy: 1.0000 - val_loss: 4.2171 - val_accuracy: 0.3250\n",
      "Epoch 133/150\n",
      "3893/3893 [==============================] - 1s 154us/sample - loss: 3.0446e-04 - accuracy: 1.0000 - val_loss: 4.2546 - val_accuracy: 0.3250\n",
      "Epoch 134/150\n",
      "3893/3893 [==============================] - 1s 150us/sample - loss: 2.8741e-04 - accuracy: 1.0000 - val_loss: 4.2256 - val_accuracy: 0.3230\n",
      "Epoch 135/150\n",
      "3893/3893 [==============================] - 1s 154us/sample - loss: 2.7076e-04 - accuracy: 1.0000 - val_loss: 4.2663 - val_accuracy: 0.3211\n",
      "Epoch 136/150\n",
      "3893/3893 [==============================] - 1s 150us/sample - loss: 2.5579e-04 - accuracy: 1.0000 - val_loss: 4.3108 - val_accuracy: 0.3250\n",
      "Epoch 137/150\n",
      "3893/3893 [==============================] - 1s 151us/sample - loss: 2.3923e-04 - accuracy: 1.0000 - val_loss: 4.3568 - val_accuracy: 0.3250\n",
      "Epoch 138/150\n",
      "3893/3893 [==============================] - 1s 153us/sample - loss: 2.2358e-04 - accuracy: 1.0000 - val_loss: 4.3462 - val_accuracy: 0.3230\n",
      "Epoch 139/150\n",
      "3893/3893 [==============================] - 1s 151us/sample - loss: 2.0951e-04 - accuracy: 1.0000 - val_loss: 4.3877 - val_accuracy: 0.3230\n",
      "Epoch 140/150\n",
      "3893/3893 [==============================] - 1s 154us/sample - loss: 1.9464e-04 - accuracy: 1.0000 - val_loss: 4.4478 - val_accuracy: 0.3211\n",
      "Epoch 141/150\n",
      "3893/3893 [==============================] - 1s 157us/sample - loss: 2.0026e-04 - accuracy: 1.0000 - val_loss: 4.4365 - val_accuracy: 0.3230\n",
      "Epoch 142/150\n",
      "3893/3893 [==============================] - 1s 173us/sample - loss: 1.7073e-04 - accuracy: 1.0000 - val_loss: 4.5191 - val_accuracy: 0.3230\n",
      "Epoch 143/150\n",
      "3893/3893 [==============================] - 1s 175us/sample - loss: 1.4717e-04 - accuracy: 1.0000 - val_loss: 4.5299 - val_accuracy: 0.3250\n",
      "Epoch 144/150\n",
      "3893/3893 [==============================] - 1s 172us/sample - loss: 1.2546e-04 - accuracy: 1.0000 - val_loss: 4.6459 - val_accuracy: 0.3114\n",
      "Epoch 145/150\n",
      "3893/3893 [==============================] - 1s 160us/sample - loss: 1.0989e-04 - accuracy: 1.0000 - val_loss: 4.7208 - val_accuracy: 0.3172\n",
      "Epoch 146/150\n",
      "3893/3893 [==============================] - 1s 176us/sample - loss: 8.8663e-05 - accuracy: 1.0000 - val_loss: 4.8315 - val_accuracy: 0.3172\n",
      "Epoch 147/150\n",
      "3893/3893 [==============================] - 1s 169us/sample - loss: 7.5151e-05 - accuracy: 1.0000 - val_loss: 4.8354 - val_accuracy: 0.3288\n",
      "Epoch 148/150\n",
      "3893/3893 [==============================] - 1s 164us/sample - loss: 7.0086e-05 - accuracy: 1.0000 - val_loss: 4.8132 - val_accuracy: 0.3308\n",
      "Epoch 149/150\n",
      "3893/3893 [==============================] - 1s 160us/sample - loss: 5.7985e-05 - accuracy: 1.0000 - val_loss: 4.9880 - val_accuracy: 0.3288\n",
      "Epoch 150/150\n",
      "3893/3893 [==============================] - 1s 152us/sample - loss: 5.1795e-05 - accuracy: 1.0000 - val_loss: 5.0442 - val_accuracy: 0.3153\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(\n",
    "    # training set\n",
    "    *dataset_split[\"train\"][:2],\n",
    "    # default batch size\n",
    "    batch_size=32,\n",
    "    # number of times the model will see each datapoint\n",
    "    epochs=150,\n",
    "    # report progress in text format\n",
    "    verbose=1,\n",
    "    # provide a validation set so the unbiased accuracy can be monitored \n",
    "    validation_data=dataset_split[\"test\"][:2],\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7408123791102514"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(dataset_split[\"test\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (20,7)\n",
    "plt.plot(history.history['accuracy'], label=\"train\")\n",
    "plt.plot(history.history['val_accuracy'], label=\"test\")\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.hlines(y=0.5, xmin=0, xmax=len(history.history[\"accuracy\"]), color=\"red\", linestyles=\"dashed\", label=\"random\")\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.legend(\n",
    "  #['train', 'test'],\n",
    "    loc='upper left')\n",
    "plt.savefig(\"../plots/experiment_2.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.load(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on training set\n",
    "\n",
    "Positive control -> it should have high accuracy since the model saw this data already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9807\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, acc = data.model.evaluate(*dataset_split[\"train\"][:2], verbose=0)\n",
    "test_str = 'Train accuracy: %.4f' % acc\n",
    "print(test_str)\n",
    "with open(test_str_txt, \"w\") as fh:\n",
    "    fh.write(test_str + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test set\n",
    "\n",
    "Experiment -> if this is high, the model actually learnt, otherwise it didn't, no matter how high the training set accuracy is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.302\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, acc = data.model.evaluate(*dataset_split[\"test\"][:2], verbose=3)\n",
    "test_str = 'Test Accuracy: %.3f' % acc\n",
    "print(test_str)\n",
    "with open(test_str_txt, \"w\") as fh:\n",
    "    fh.write(test_str + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.044247956986123"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "data.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-9f3555f53600>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'summary'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7408123791102514"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(dataset_split[\"test\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted score: 0.997\n",
      "Predicted class: 0\n",
      "Should be 1\n"
     ]
    }
   ],
   "source": [
    "#data.model.predict([dataset_split[\"test\"][0][0,:].tolist()])\n",
    "# make a prediction\n",
    "\n",
    "yhat = data.predict([dataset_split[\"test\"][0][4,:].tolist()])\n",
    "print('Predicted score: %.3f' % list(yhat.values())[0])\n",
    "print('Predicted class: %d' % list(yhat.keys())[0])\n",
    "print(f\"Should be {dataset_split['test'][1][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.get_labels(encode=False)[:3]\n",
    "# data.get_labels()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vibflysleep/anaconda3/envs/TF/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc197e916f543c99fa7b6a1c9061500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/517 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_scores = []\n",
    "class_preds = []\n",
    "\n",
    "test_data = dataset_split[\"test\"][0]\n",
    "\n",
    "for i in tqdm(range(test_data.shape[0])):\n",
    "    yhat = data.predict([test_data[i,:].tolist()])\n",
    "    class_preds.append(list(yhat.keys())[0])\n",
    "    class_scores.append(list(yhat.values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrue = dataset_split[\"test\"][1]\n",
    "\n",
    "summ = pd.DataFrame({\n",
    "    \"yhat\": class_scores,\n",
    "    \"class\": class_preds,\n",
    "    \"ytrue\": ytrue,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yhat</th>\n",
       "      <th>class</th>\n",
       "      <th>ytrue</th>\n",
       "      <th>correct_pred</th>\n",
       "      <th>incorrect_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.960939</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.551575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.997476</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.996633</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>0.991901</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.993143</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.997333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         yhat  class  ytrue  correct_pred  incorrect_pred\n",
       "0    0.960939      1      1          True           False\n",
       "1    0.551575      0      0          True           False\n",
       "2    0.997476      1      1          True           False\n",
       "3    1.000000      1      0         False            True\n",
       "4    0.996633      0      0          True           False\n",
       "..        ...    ...    ...           ...             ...\n",
       "512  0.991901      0      0          True           False\n",
       "513  0.993143      0      1         False            True\n",
       "514  1.000000      1      1          True           False\n",
       "515  0.997333      1      1          True           False\n",
       "516  1.000000      0      1         False            True\n",
       "\n",
       "[517 rows x 5 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ[\"correct_pred\"] =  summ.values[:,1] == summ.values[:,2]\n",
    "summ[\"incorrect_pred\"] = summ.values[:,1] != summ.values[:,2]\n",
    "summ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_split[\"test\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can only merge Series or DataFrame objects, a <class 'numpy.ndarray'> was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-fc85c419e450>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/TF/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     )\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     ):\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0m_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_operand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0m_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_operand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_left\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/TF/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_validate_operand\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   2147\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m         raise TypeError(\n\u001b[0;32m-> 2149\u001b[0;31m             \u001b[0;34mf\"Can only merge Series or DataFrame objects, a {type(obj)} was passed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2150\u001b[0m         )\n\u001b[1;32m   2151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can only merge Series or DataFrame objects, a <class 'numpy.ndarray'> was passed"
     ]
    }
   ],
   "source": [
    "test_obs = pd.merge(dataset_split[\"test\"][2], data.obs, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_obs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-f5c7155c0be0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msumm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msumm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_obs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_obs' is not defined"
     ]
    }
   ],
   "source": [
    "summ=pd.concat([summ, test_obs],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yhat</th>\n",
       "      <th>class</th>\n",
       "      <th>ytrue</th>\n",
       "      <th>correct_pred</th>\n",
       "      <th>incorrect_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.960939</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.551575</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.997476</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.996633</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       yhat  class  ytrue  correct_pred  incorrect_pred\n",
       "0  0.960939      1      1          True           False\n",
       "1  0.551575      0      0          True           False\n",
       "2  0.997476      1      1          True           False\n",
       "3  1.000000      1      0         False            True\n",
       "4  0.996633      0      0          True           False"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yhat</th>\n",
       "      <th>class</th>\n",
       "      <th>ytrue</th>\n",
       "      <th>correct_pred</th>\n",
       "      <th>incorrect_pred</th>\n",
       "      <th>Clusterings.0</th>\n",
       "      <th>Clusterings.1</th>\n",
       "      <th>Clusterings.2</th>\n",
       "      <th>Clusterings.3</th>\n",
       "      <th>Clusterings.4</th>\n",
       "      <th>...</th>\n",
       "      <th>Embeddings_Y.2</th>\n",
       "      <th>Percent_mito</th>\n",
       "      <th>detected</th>\n",
       "      <th>discard</th>\n",
       "      <th>nGene</th>\n",
       "      <th>nUMI</th>\n",
       "      <th>propZero</th>\n",
       "      <th>sizeFactor</th>\n",
       "      <th>sum</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Condition</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ZT 14 SD</th>\n",
       "      <td>31.197010</td>\n",
       "      <td>94</td>\n",
       "      <td>96</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>128</td>\n",
       "      <td>96</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>29.591022</td>\n",
       "      <td>3.640718</td>\n",
       "      <td>58805.0</td>\n",
       "      <td>2</td>\n",
       "      <td>58805</td>\n",
       "      <td>205914.0</td>\n",
       "      <td>26.116558</td>\n",
       "      <td>29.317875</td>\n",
       "      <td>205914.0</td>\n",
       "      <td>205914.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZT 14 sleep</th>\n",
       "      <td>77.802381</td>\n",
       "      <td>231</td>\n",
       "      <td>237</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>261</td>\n",
       "      <td>316</td>\n",
       "      <td>237</td>\n",
       "      <td>316</td>\n",
       "      <td>316</td>\n",
       "      <td>...</td>\n",
       "      <td>34.708839</td>\n",
       "      <td>10.276807</td>\n",
       "      <td>145030.0</td>\n",
       "      <td>9</td>\n",
       "      <td>145030</td>\n",
       "      <td>521367.0</td>\n",
       "      <td>64.489746</td>\n",
       "      <td>74.725090</td>\n",
       "      <td>521367.0</td>\n",
       "      <td>521367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZT 2 rebound 12h SD</th>\n",
       "      <td>226.487216</td>\n",
       "      <td>443</td>\n",
       "      <td>428</td>\n",
       "      <td>219</td>\n",
       "      <td>10</td>\n",
       "      <td>735</td>\n",
       "      <td>916</td>\n",
       "      <td>687</td>\n",
       "      <td>916</td>\n",
       "      <td>916</td>\n",
       "      <td>...</td>\n",
       "      <td>17.029377</td>\n",
       "      <td>25.054203</td>\n",
       "      <td>436838.0</td>\n",
       "      <td>30</td>\n",
       "      <td>436838</td>\n",
       "      <td>1795278.0</td>\n",
       "      <td>185.294342</td>\n",
       "      <td>255.774628</td>\n",
       "      <td>1795278.0</td>\n",
       "      <td>1795278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZT 2 sleep drive 14h SD</th>\n",
       "      <td>144.128526</td>\n",
       "      <td>229</td>\n",
       "      <td>226</td>\n",
       "      <td>140</td>\n",
       "      <td>5</td>\n",
       "      <td>459</td>\n",
       "      <td>580</td>\n",
       "      <td>435</td>\n",
       "      <td>580</td>\n",
       "      <td>580</td>\n",
       "      <td>...</td>\n",
       "      <td>8.989573</td>\n",
       "      <td>15.420468</td>\n",
       "      <td>267025.0</td>\n",
       "      <td>18</td>\n",
       "      <td>267025</td>\n",
       "      <td>1004200.0</td>\n",
       "      <td>118.284142</td>\n",
       "      <td>141.358109</td>\n",
       "      <td>1004200.0</td>\n",
       "      <td>1004200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZT 20 midline cross</th>\n",
       "      <td>88.244600</td>\n",
       "      <td>177</td>\n",
       "      <td>178</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>283</td>\n",
       "      <td>356</td>\n",
       "      <td>267</td>\n",
       "      <td>356</td>\n",
       "      <td>356</td>\n",
       "      <td>...</td>\n",
       "      <td>22.005627</td>\n",
       "      <td>6.570885</td>\n",
       "      <td>175916.0</td>\n",
       "      <td>12</td>\n",
       "      <td>175916</td>\n",
       "      <td>673128.0</td>\n",
       "      <td>71.399597</td>\n",
       "      <td>96.645912</td>\n",
       "      <td>673128.0</td>\n",
       "      <td>673128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZT 20 sleep</th>\n",
       "      <td>287.025583</td>\n",
       "      <td>548</td>\n",
       "      <td>528</td>\n",
       "      <td>262</td>\n",
       "      <td>36</td>\n",
       "      <td>926</td>\n",
       "      <td>1192</td>\n",
       "      <td>894</td>\n",
       "      <td>1192</td>\n",
       "      <td>1192</td>\n",
       "      <td>...</td>\n",
       "      <td>100.646004</td>\n",
       "      <td>24.244793</td>\n",
       "      <td>548298.0</td>\n",
       "      <td>49</td>\n",
       "      <td>548298</td>\n",
       "      <td>2002588.0</td>\n",
       "      <td>243.142776</td>\n",
       "      <td>301.424683</td>\n",
       "      <td>2002588.0</td>\n",
       "      <td>2002588.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZT 20 sleep deprivation</th>\n",
       "      <td>215.223485</td>\n",
       "      <td>401</td>\n",
       "      <td>369</td>\n",
       "      <td>194</td>\n",
       "      <td>30</td>\n",
       "      <td>696</td>\n",
       "      <td>896</td>\n",
       "      <td>672</td>\n",
       "      <td>896</td>\n",
       "      <td>896</td>\n",
       "      <td>...</td>\n",
       "      <td>71.477463</td>\n",
       "      <td>21.231804</td>\n",
       "      <td>411345.0</td>\n",
       "      <td>36</td>\n",
       "      <td>411345</td>\n",
       "      <td>1459433.0</td>\n",
       "      <td>182.844925</td>\n",
       "      <td>219.431213</td>\n",
       "      <td>1459433.0</td>\n",
       "      <td>1459433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZT 8 20h SD</th>\n",
       "      <td>63.190920</td>\n",
       "      <td>342</td>\n",
       "      <td>362</td>\n",
       "      <td>55</td>\n",
       "      <td>14</td>\n",
       "      <td>207</td>\n",
       "      <td>276</td>\n",
       "      <td>207</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>...</td>\n",
       "      <td>40.386845</td>\n",
       "      <td>6.251998</td>\n",
       "      <td>114716.0</td>\n",
       "      <td>20</td>\n",
       "      <td>114716</td>\n",
       "      <td>395232.0</td>\n",
       "      <td>57.522663</td>\n",
       "      <td>62.329391</td>\n",
       "      <td>395232.0</td>\n",
       "      <td>395232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZT 8 gab</th>\n",
       "      <td>76.115061</td>\n",
       "      <td>420</td>\n",
       "      <td>438</td>\n",
       "      <td>71</td>\n",
       "      <td>10</td>\n",
       "      <td>251</td>\n",
       "      <td>324</td>\n",
       "      <td>243</td>\n",
       "      <td>324</td>\n",
       "      <td>324</td>\n",
       "      <td>...</td>\n",
       "      <td>72.935493</td>\n",
       "      <td>7.518210</td>\n",
       "      <td>129407.0</td>\n",
       "      <td>21</td>\n",
       "      <td>129407</td>\n",
       "      <td>400524.0</td>\n",
       "      <td>68.052826</td>\n",
       "      <td>63.522930</td>\n",
       "      <td>400524.0</td>\n",
       "      <td>400524.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZT 8 wake</th>\n",
       "      <td>158.688815</td>\n",
       "      <td>423</td>\n",
       "      <td>411</td>\n",
       "      <td>155</td>\n",
       "      <td>7</td>\n",
       "      <td>486</td>\n",
       "      <td>648</td>\n",
       "      <td>486</td>\n",
       "      <td>648</td>\n",
       "      <td>648</td>\n",
       "      <td>...</td>\n",
       "      <td>142.173859</td>\n",
       "      <td>9.226872</td>\n",
       "      <td>287857.0</td>\n",
       "      <td>15</td>\n",
       "      <td>287857</td>\n",
       "      <td>923083.0</td>\n",
       "      <td>133.199905</td>\n",
       "      <td>150.204742</td>\n",
       "      <td>923083.0</td>\n",
       "      <td>923083.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZT 8 wake stimulation</th>\n",
       "      <td>47.570649</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>192</td>\n",
       "      <td>144</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>...</td>\n",
       "      <td>37.510910</td>\n",
       "      <td>1.725349</td>\n",
       "      <td>107851.0</td>\n",
       "      <td>16</td>\n",
       "      <td>107851</td>\n",
       "      <td>469028.0</td>\n",
       "      <td>37.209503</td>\n",
       "      <td>79.552223</td>\n",
       "      <td>469028.0</td>\n",
       "      <td>469028.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               yhat  class  ytrue  correct_pred  \\\n",
       "Condition                                                         \n",
       "ZT 14 SD                  31.197010     94     96            31   \n",
       "ZT 14 sleep               77.802381    231    237            76   \n",
       "ZT 2 rebound 12h SD      226.487216    443    428           219   \n",
       "ZT 2 sleep drive 14h SD  144.128526    229    226           140   \n",
       "ZT 20 midline cross       88.244600    177    178            88   \n",
       "ZT 20 sleep              287.025583    548    528           262   \n",
       "ZT 20 sleep deprivation  215.223485    401    369           194   \n",
       "ZT 8 20h SD               63.190920    342    362            55   \n",
       "ZT 8 gab                  76.115061    420    438            71   \n",
       "ZT 8 wake                158.688815    423    411           155   \n",
       "ZT 8 wake stimulation     47.570649      4      0            47   \n",
       "\n",
       "                         incorrect_pred  Clusterings.0  Clusterings.1  \\\n",
       "Condition                                                               \n",
       "ZT 14 SD                              1             96            128   \n",
       "ZT 14 sleep                           3            261            316   \n",
       "ZT 2 rebound 12h SD                  10            735            916   \n",
       "ZT 2 sleep drive 14h SD               5            459            580   \n",
       "ZT 20 midline cross                   1            283            356   \n",
       "ZT 20 sleep                          36            926           1192   \n",
       "ZT 20 sleep deprivation              30            696            896   \n",
       "ZT 8 20h SD                          14            207            276   \n",
       "ZT 8 gab                             10            251            324   \n",
       "ZT 8 wake                             7            486            648   \n",
       "ZT 8 wake stimulation                 1            160            192   \n",
       "\n",
       "                         Clusterings.2  Clusterings.3  Clusterings.4  ...  \\\n",
       "Condition                                                             ...   \n",
       "ZT 14 SD                            96            128            128  ...   \n",
       "ZT 14 sleep                        237            316            316  ...   \n",
       "ZT 2 rebound 12h SD                687            916            916  ...   \n",
       "ZT 2 sleep drive 14h SD            435            580            580  ...   \n",
       "ZT 20 midline cross                267            356            356  ...   \n",
       "ZT 20 sleep                        894           1192           1192  ...   \n",
       "ZT 20 sleep deprivation            672            896            896  ...   \n",
       "ZT 8 20h SD                        207            276            276  ...   \n",
       "ZT 8 gab                           243            324            324  ...   \n",
       "ZT 8 wake                          486            648            648  ...   \n",
       "ZT 8 wake stimulation              144            192            192  ...   \n",
       "\n",
       "                         Embeddings_Y.2  Percent_mito  detected  discard  \\\n",
       "Condition                                                                  \n",
       "ZT 14 SD                      29.591022      3.640718   58805.0        2   \n",
       "ZT 14 sleep                   34.708839     10.276807  145030.0        9   \n",
       "ZT 2 rebound 12h SD           17.029377     25.054203  436838.0       30   \n",
       "ZT 2 sleep drive 14h SD        8.989573     15.420468  267025.0       18   \n",
       "ZT 20 midline cross           22.005627      6.570885  175916.0       12   \n",
       "ZT 20 sleep                  100.646004     24.244793  548298.0       49   \n",
       "ZT 20 sleep deprivation       71.477463     21.231804  411345.0       36   \n",
       "ZT 8 20h SD                   40.386845      6.251998  114716.0       20   \n",
       "ZT 8 gab                      72.935493      7.518210  129407.0       21   \n",
       "ZT 8 wake                    142.173859      9.226872  287857.0       15   \n",
       "ZT 8 wake stimulation         37.510910      1.725349  107851.0       16   \n",
       "\n",
       "                          nGene       nUMI    propZero  sizeFactor        sum  \\\n",
       "Condition                                                                       \n",
       "ZT 14 SD                  58805   205914.0   26.116558   29.317875   205914.0   \n",
       "ZT 14 sleep              145030   521367.0   64.489746   74.725090   521367.0   \n",
       "ZT 2 rebound 12h SD      436838  1795278.0  185.294342  255.774628  1795278.0   \n",
       "ZT 2 sleep drive 14h SD  267025  1004200.0  118.284142  141.358109  1004200.0   \n",
       "ZT 20 midline cross      175916   673128.0   71.399597   96.645912   673128.0   \n",
       "ZT 20 sleep              548298  2002588.0  243.142776  301.424683  2002588.0   \n",
       "ZT 20 sleep deprivation  411345  1459433.0  182.844925  219.431213  1459433.0   \n",
       "ZT 8 20h SD              114716   395232.0   57.522663   62.329391   395232.0   \n",
       "ZT 8 gab                 129407   400524.0   68.052826   63.522930   400524.0   \n",
       "ZT 8 wake                287857   923083.0  133.199905  150.204742   923083.0   \n",
       "ZT 8 wake stimulation    107851   469028.0   37.209503   79.552223   469028.0   \n",
       "\n",
       "                             total  \n",
       "Condition                           \n",
       "ZT 14 SD                  205914.0  \n",
       "ZT 14 sleep               521367.0  \n",
       "ZT 2 rebound 12h SD      1795278.0  \n",
       "ZT 2 sleep drive 14h SD  1004200.0  \n",
       "ZT 20 midline cross       673128.0  \n",
       "ZT 20 sleep              2002588.0  \n",
       "ZT 20 sleep deprivation  1459433.0  \n",
       "ZT 8 20h SD               395232.0  \n",
       "ZT 8 gab                  400524.0  \n",
       "ZT 8 wake                 923083.0  \n",
       "ZT 8 wake stimulation     469028.0  \n",
       "\n",
       "[11 rows x 29 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ.groupby(\"Condition\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yhat</th>\n",
       "      <th>class</th>\n",
       "      <th>ytrue</th>\n",
       "      <th>correct_pred</th>\n",
       "      <th>incorrect_pred</th>\n",
       "      <th>Clusterings.0</th>\n",
       "      <th>Clusterings.1</th>\n",
       "      <th>Clusterings.2</th>\n",
       "      <th>Clusterings.3</th>\n",
       "      <th>Clusterings.4</th>\n",
       "      <th>...</th>\n",
       "      <th>Embeddings_Y.2</th>\n",
       "      <th>Percent_mito</th>\n",
       "      <th>detected</th>\n",
       "      <th>discard</th>\n",
       "      <th>nGene</th>\n",
       "      <th>nUMI</th>\n",
       "      <th>propZero</th>\n",
       "      <th>sizeFactor</th>\n",
       "      <th>sum</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genotype</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>line_287</th>\n",
       "      <td>155.409705</td>\n",
       "      <td>579</td>\n",
       "      <td>573</td>\n",
       "      <td>144</td>\n",
       "      <td>16</td>\n",
       "      <td>488</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "      <td>640</td>\n",
       "      <td>640</td>\n",
       "      <td>...</td>\n",
       "      <td>107.590340</td>\n",
       "      <td>13.756172</td>\n",
       "      <td>260098.0</td>\n",
       "      <td>15</td>\n",
       "      <td>260098</td>\n",
       "      <td>798320.0</td>\n",
       "      <td>133.977188</td>\n",
       "      <td>119.779808</td>\n",
       "      <td>798320.0</td>\n",
       "      <td>798320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_303</th>\n",
       "      <td>162.372277</td>\n",
       "      <td>396</td>\n",
       "      <td>397</td>\n",
       "      <td>146</td>\n",
       "      <td>20</td>\n",
       "      <td>522</td>\n",
       "      <td>664</td>\n",
       "      <td>498</td>\n",
       "      <td>664</td>\n",
       "      <td>664</td>\n",
       "      <td>...</td>\n",
       "      <td>44.577148</td>\n",
       "      <td>15.555780</td>\n",
       "      <td>320399.0</td>\n",
       "      <td>27</td>\n",
       "      <td>320399</td>\n",
       "      <td>1309891.0</td>\n",
       "      <td>133.944077</td>\n",
       "      <td>192.866348</td>\n",
       "      <td>1309891.0</td>\n",
       "      <td>1309891.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_313</th>\n",
       "      <td>68.884057</td>\n",
       "      <td>68</td>\n",
       "      <td>67</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>234</td>\n",
       "      <td>280</td>\n",
       "      <td>210</td>\n",
       "      <td>280</td>\n",
       "      <td>280</td>\n",
       "      <td>...</td>\n",
       "      <td>24.431211</td>\n",
       "      <td>3.838529</td>\n",
       "      <td>151599.0</td>\n",
       "      <td>15</td>\n",
       "      <td>151599</td>\n",
       "      <td>621403.0</td>\n",
       "      <td>54.832516</td>\n",
       "      <td>98.771049</td>\n",
       "      <td>621403.0</td>\n",
       "      <td>621403.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_359</th>\n",
       "      <td>15.751792</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>17.128075</td>\n",
       "      <td>0.794291</td>\n",
       "      <td>31909.0</td>\n",
       "      <td>4</td>\n",
       "      <td>31909</td>\n",
       "      <td>124335.0</td>\n",
       "      <td>12.807504</td>\n",
       "      <td>20.968523</td>\n",
       "      <td>124335.0</td>\n",
       "      <td>124335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_379</th>\n",
       "      <td>259.685716</td>\n",
       "      <td>655</td>\n",
       "      <td>656</td>\n",
       "      <td>244</td>\n",
       "      <td>26</td>\n",
       "      <td>850</td>\n",
       "      <td>1080</td>\n",
       "      <td>810</td>\n",
       "      <td>1080</td>\n",
       "      <td>1080</td>\n",
       "      <td>...</td>\n",
       "      <td>87.123665</td>\n",
       "      <td>26.131338</td>\n",
       "      <td>503289.0</td>\n",
       "      <td>50</td>\n",
       "      <td>503289</td>\n",
       "      <td>1864700.0</td>\n",
       "      <td>219.645920</td>\n",
       "      <td>280.476501</td>\n",
       "      <td>1864700.0</td>\n",
       "      <td>1864700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_441</th>\n",
       "      <td>242.670214</td>\n",
       "      <td>524</td>\n",
       "      <td>515</td>\n",
       "      <td>229</td>\n",
       "      <td>19</td>\n",
       "      <td>776</td>\n",
       "      <td>992</td>\n",
       "      <td>744</td>\n",
       "      <td>992</td>\n",
       "      <td>992</td>\n",
       "      <td>...</td>\n",
       "      <td>110.844986</td>\n",
       "      <td>20.976332</td>\n",
       "      <td>446411.0</td>\n",
       "      <td>39</td>\n",
       "      <td>446411</td>\n",
       "      <td>1567675.0</td>\n",
       "      <td>203.336563</td>\n",
       "      <td>234.721939</td>\n",
       "      <td>1567675.0</td>\n",
       "      <td>1567675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_646</th>\n",
       "      <td>109.026463</td>\n",
       "      <td>353</td>\n",
       "      <td>351</td>\n",
       "      <td>106</td>\n",
       "      <td>7</td>\n",
       "      <td>387</td>\n",
       "      <td>452</td>\n",
       "      <td>339</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>...</td>\n",
       "      <td>38.902752</td>\n",
       "      <td>11.826299</td>\n",
       "      <td>203800.0</td>\n",
       "      <td>20</td>\n",
       "      <td>203800</td>\n",
       "      <td>771933.0</td>\n",
       "      <td>92.609802</td>\n",
       "      <td>115.383301</td>\n",
       "      <td>771933.0</td>\n",
       "      <td>771933.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_88</th>\n",
       "      <td>247.688806</td>\n",
       "      <td>320</td>\n",
       "      <td>306</td>\n",
       "      <td>239</td>\n",
       "      <td>14</td>\n",
       "      <td>767</td>\n",
       "      <td>1012</td>\n",
       "      <td>759</td>\n",
       "      <td>1012</td>\n",
       "      <td>1012</td>\n",
       "      <td>...</td>\n",
       "      <td>104.420280</td>\n",
       "      <td>22.582960</td>\n",
       "      <td>468627.0</td>\n",
       "      <td>29</td>\n",
       "      <td>468627</td>\n",
       "      <td>1627937.0</td>\n",
       "      <td>206.113861</td>\n",
       "      <td>245.407028</td>\n",
       "      <td>1627937.0</td>\n",
       "      <td>1627937.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_892</th>\n",
       "      <td>63.732961</td>\n",
       "      <td>100</td>\n",
       "      <td>101</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>256</td>\n",
       "      <td>192</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.215744</td>\n",
       "      <td>6.604895</td>\n",
       "      <td>125218.0</td>\n",
       "      <td>9</td>\n",
       "      <td>125218</td>\n",
       "      <td>527045.0</td>\n",
       "      <td>51.471935</td>\n",
       "      <td>72.548286</td>\n",
       "      <td>527045.0</td>\n",
       "      <td>527045.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_908</th>\n",
       "      <td>90.452254</td>\n",
       "      <td>313</td>\n",
       "      <td>307</td>\n",
       "      <td>83</td>\n",
       "      <td>13</td>\n",
       "      <td>288</td>\n",
       "      <td>384</td>\n",
       "      <td>288</td>\n",
       "      <td>384</td>\n",
       "      <td>384</td>\n",
       "      <td>...</td>\n",
       "      <td>51.652294</td>\n",
       "      <td>9.095512</td>\n",
       "      <td>171738.0</td>\n",
       "      <td>20</td>\n",
       "      <td>171738</td>\n",
       "      <td>636536.0</td>\n",
       "      <td>78.817612</td>\n",
       "      <td>93.364006</td>\n",
       "      <td>636536.0</td>\n",
       "      <td>636536.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                yhat  class  ytrue  correct_pred  incorrect_pred  \\\n",
       "Genotype                                                           \n",
       "line_287  155.409705    579    573           144              16   \n",
       "line_303  162.372277    396    397           146              20   \n",
       "line_313   68.884057     68     67            69               1   \n",
       "line_359   15.751792      4      0            15               1   \n",
       "line_379  259.685716    655    656           244              26   \n",
       "line_441  242.670214    524    515           229              19   \n",
       "line_646  109.026463    353    351           106               7   \n",
       "line_88   247.688806    320    306           239              14   \n",
       "line_892   63.732961    100    101            63               1   \n",
       "line_908   90.452254    313    307            83              13   \n",
       "\n",
       "          Clusterings.0  Clusterings.1  Clusterings.2  Clusterings.3  \\\n",
       "Genotype                                                               \n",
       "line_287            488            640            480            640   \n",
       "line_303            522            664            498            664   \n",
       "line_313            234            280            210            280   \n",
       "line_359             48             64             48             64   \n",
       "line_379            850           1080            810           1080   \n",
       "line_441            776            992            744            992   \n",
       "line_646            387            452            339            452   \n",
       "line_88             767           1012            759           1012   \n",
       "line_892            200            256            192            256   \n",
       "line_908            288            384            288            384   \n",
       "\n",
       "          Clusterings.4  ...  Embeddings_Y.2  Percent_mito  detected  discard  \\\n",
       "Genotype                 ...                                                    \n",
       "line_287            640  ...      107.590340     13.756172  260098.0       15   \n",
       "line_303            664  ...       44.577148     15.555780  320399.0       27   \n",
       "line_313            280  ...       24.431211      3.838529  151599.0       15   \n",
       "line_359             64  ...       17.128075      0.794291   31909.0        4   \n",
       "line_379           1080  ...       87.123665     26.131338  503289.0       50   \n",
       "line_441            992  ...      110.844986     20.976332  446411.0       39   \n",
       "line_646            452  ...       38.902752     11.826299  203800.0       20   \n",
       "line_88            1012  ...      104.420280     22.582960  468627.0       29   \n",
       "line_892            256  ...       -9.215744      6.604895  125218.0        9   \n",
       "line_908            384  ...       51.652294      9.095512  171738.0       20   \n",
       "\n",
       "           nGene       nUMI    propZero  sizeFactor        sum      total  \n",
       "Genotype                                                                   \n",
       "line_287  260098   798320.0  133.977188  119.779808   798320.0   798320.0  \n",
       "line_303  320399  1309891.0  133.944077  192.866348  1309891.0  1309891.0  \n",
       "line_313  151599   621403.0   54.832516   98.771049   621403.0   621403.0  \n",
       "line_359   31909   124335.0   12.807504   20.968523   124335.0   124335.0  \n",
       "line_379  503289  1864700.0  219.645920  280.476501  1864700.0  1864700.0  \n",
       "line_441  446411  1567675.0  203.336563  234.721939  1567675.0  1567675.0  \n",
       "line_646  203800   771933.0   92.609802  115.383301   771933.0   771933.0  \n",
       "line_88   468627  1627937.0  206.113861  245.407028  1627937.0  1627937.0  \n",
       "line_892  125218   527045.0   51.471935   72.548286   527045.0   527045.0  \n",
       "line_908  171738   636536.0   78.817612   93.364006   636536.0   636536.0  \n",
       "\n",
       "[10 rows x 29 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ.groupby(\"Genotype\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yhat</th>\n",
       "      <th>class</th>\n",
       "      <th>ytrue</th>\n",
       "      <th>correct_pred</th>\n",
       "      <th>incorrect_pred</th>\n",
       "      <th>Clusterings.0</th>\n",
       "      <th>Clusterings.1</th>\n",
       "      <th>Clusterings.2</th>\n",
       "      <th>Clusterings.3</th>\n",
       "      <th>Clusterings.4</th>\n",
       "      <th>...</th>\n",
       "      <th>Embeddings_Y.2</th>\n",
       "      <th>Percent_mito</th>\n",
       "      <th>detected</th>\n",
       "      <th>discard</th>\n",
       "      <th>nGene</th>\n",
       "      <th>nUMI</th>\n",
       "      <th>propZero</th>\n",
       "      <th>sizeFactor</th>\n",
       "      <th>sum</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20180419</th>\n",
       "      <td>234.614130</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>8</td>\n",
       "      <td>760</td>\n",
       "      <td>960</td>\n",
       "      <td>720</td>\n",
       "      <td>960</td>\n",
       "      <td>960</td>\n",
       "      <td>...</td>\n",
       "      <td>174.983536</td>\n",
       "      <td>10.607087</td>\n",
       "      <td>461040.0</td>\n",
       "      <td>51</td>\n",
       "      <td>461040</td>\n",
       "      <td>1645433.0</td>\n",
       "      <td>193.872940</td>\n",
       "      <td>273.382324</td>\n",
       "      <td>1645433.0</td>\n",
       "      <td>1645433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20191009</th>\n",
       "      <td>337.009635</td>\n",
       "      <td>370</td>\n",
       "      <td>342</td>\n",
       "      <td>329</td>\n",
       "      <td>13</td>\n",
       "      <td>1066</td>\n",
       "      <td>1368</td>\n",
       "      <td>1026</td>\n",
       "      <td>1368</td>\n",
       "      <td>1368</td>\n",
       "      <td>...</td>\n",
       "      <td>-48.366936</td>\n",
       "      <td>45.411392</td>\n",
       "      <td>624681.0</td>\n",
       "      <td>37</td>\n",
       "      <td>624681</td>\n",
       "      <td>2294930.0</td>\n",
       "      <td>279.500641</td>\n",
       "      <td>323.791565</td>\n",
       "      <td>2294930.0</td>\n",
       "      <td>2294930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20191023</th>\n",
       "      <td>347.025318</td>\n",
       "      <td>696</td>\n",
       "      <td>698</td>\n",
       "      <td>340</td>\n",
       "      <td>9</td>\n",
       "      <td>1119</td>\n",
       "      <td>1396</td>\n",
       "      <td>1047</td>\n",
       "      <td>1396</td>\n",
       "      <td>1396</td>\n",
       "      <td>...</td>\n",
       "      <td>74.231094</td>\n",
       "      <td>27.350485</td>\n",
       "      <td>693884.0</td>\n",
       "      <td>50</td>\n",
       "      <td>693884</td>\n",
       "      <td>2869214.0</td>\n",
       "      <td>279.576874</td>\n",
       "      <td>411.135834</td>\n",
       "      <td>2869214.0</td>\n",
       "      <td>2869214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20191106</th>\n",
       "      <td>155.878722</td>\n",
       "      <td>466</td>\n",
       "      <td>474</td>\n",
       "      <td>154</td>\n",
       "      <td>4</td>\n",
       "      <td>498</td>\n",
       "      <td>632</td>\n",
       "      <td>474</td>\n",
       "      <td>632</td>\n",
       "      <td>632</td>\n",
       "      <td>...</td>\n",
       "      <td>82.272377</td>\n",
       "      <td>19.257898</td>\n",
       "      <td>284178.0</td>\n",
       "      <td>14</td>\n",
       "      <td>284178</td>\n",
       "      <td>998975.0</td>\n",
       "      <td>129.567978</td>\n",
       "      <td>142.707123</td>\n",
       "      <td>998975.0</td>\n",
       "      <td>998975.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20200902</th>\n",
       "      <td>123.954674</td>\n",
       "      <td>578</td>\n",
       "      <td>548</td>\n",
       "      <td>81</td>\n",
       "      <td>56</td>\n",
       "      <td>419</td>\n",
       "      <td>548</td>\n",
       "      <td>411</td>\n",
       "      <td>548</td>\n",
       "      <td>548</td>\n",
       "      <td>...</td>\n",
       "      <td>106.674614</td>\n",
       "      <td>9.142261</td>\n",
       "      <td>239939.0</td>\n",
       "      <td>31</td>\n",
       "      <td>239939</td>\n",
       "      <td>825073.0</td>\n",
       "      <td>112.994095</td>\n",
       "      <td>130.569183</td>\n",
       "      <td>825073.0</td>\n",
       "      <td>825073.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20200916</th>\n",
       "      <td>158.344620</td>\n",
       "      <td>817</td>\n",
       "      <td>845</td>\n",
       "      <td>147</td>\n",
       "      <td>22</td>\n",
       "      <td>515</td>\n",
       "      <td>676</td>\n",
       "      <td>507</td>\n",
       "      <td>676</td>\n",
       "      <td>676</td>\n",
       "      <td>...</td>\n",
       "      <td>138.321213</td>\n",
       "      <td>14.019900</td>\n",
       "      <td>281692.0</td>\n",
       "      <td>23</td>\n",
       "      <td>281692</td>\n",
       "      <td>897814.0</td>\n",
       "      <td>140.816711</td>\n",
       "      <td>140.956940</td>\n",
       "      <td>897814.0</td>\n",
       "      <td>897814.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20200924</th>\n",
       "      <td>58.847145</td>\n",
       "      <td>354</td>\n",
       "      <td>366</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>183</td>\n",
       "      <td>244</td>\n",
       "      <td>183</td>\n",
       "      <td>244</td>\n",
       "      <td>244</td>\n",
       "      <td>...</td>\n",
       "      <td>49.339127</td>\n",
       "      <td>5.373086</td>\n",
       "      <td>97674.0</td>\n",
       "      <td>22</td>\n",
       "      <td>97674</td>\n",
       "      <td>318336.0</td>\n",
       "      <td>51.227715</td>\n",
       "      <td>51.743824</td>\n",
       "      <td>318336.0</td>\n",
       "      <td>318336.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                yhat  class  ytrue  correct_pred  incorrect_pred  \\\n",
       "Run                                                                \n",
       "20180419  234.614130     31      0           232               8   \n",
       "20191009  337.009635    370    342           329              13   \n",
       "20191023  347.025318    696    698           340               9   \n",
       "20191106  155.878722    466    474           154               4   \n",
       "20200902  123.954674    578    548            81              56   \n",
       "20200916  158.344620    817    845           147              22   \n",
       "20200924   58.847145    354    366            55               6   \n",
       "\n",
       "          Clusterings.0  Clusterings.1  Clusterings.2  Clusterings.3  \\\n",
       "Run                                                                    \n",
       "20180419            760            960            720            960   \n",
       "20191009           1066           1368           1026           1368   \n",
       "20191023           1119           1396           1047           1396   \n",
       "20191106            498            632            474            632   \n",
       "20200902            419            548            411            548   \n",
       "20200916            515            676            507            676   \n",
       "20200924            183            244            183            244   \n",
       "\n",
       "          Clusterings.4  ...  Embeddings_Y.2  Percent_mito  detected  discard  \\\n",
       "Run                      ...                                                    \n",
       "20180419            960  ...      174.983536     10.607087  461040.0       51   \n",
       "20191009           1368  ...      -48.366936     45.411392  624681.0       37   \n",
       "20191023           1396  ...       74.231094     27.350485  693884.0       50   \n",
       "20191106            632  ...       82.272377     19.257898  284178.0       14   \n",
       "20200902            548  ...      106.674614      9.142261  239939.0       31   \n",
       "20200916            676  ...      138.321213     14.019900  281692.0       23   \n",
       "20200924            244  ...       49.339127      5.373086   97674.0       22   \n",
       "\n",
       "           nGene       nUMI    propZero  sizeFactor        sum      total  \n",
       "Run                                                                        \n",
       "20180419  461040  1645433.0  193.872940  273.382324  1645433.0  1645433.0  \n",
       "20191009  624681  2294930.0  279.500641  323.791565  2294930.0  2294930.0  \n",
       "20191023  693884  2869214.0  279.576874  411.135834  2869214.0  2869214.0  \n",
       "20191106  284178   998975.0  129.567978  142.707123   998975.0   998975.0  \n",
       "20200902  239939   825073.0  112.994095  130.569183   825073.0   825073.0  \n",
       "20200916  281692   897814.0  140.816711  140.956940   897814.0   897814.0  \n",
       "20200924   97674   318336.0   51.227715   51.743824   318336.0   318336.0  \n",
       "\n",
       "[7 rows x 29 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summ.groupby(\"Run\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ.to_csv(summary_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZT 20 sleep                271\n",
       "ZT 20 sleep deprivation    230\n",
       "ZT 2 rebound 12h SD        208\n",
       "ZT 2 sleep drive 14h SD    167\n",
       "ZT 8 wake                  155\n",
       "ZT 14 sleep                 90\n",
       "ZT 20 midline cross         87\n",
       "ZT 8 gab                    82\n",
       "ZT 8 20h SD                 81\n",
       "ZT 14 SD                    45\n",
       "ZT 8 wake stimulation       40\n",
       "Name: Condition, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summ[\"Condition\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # data.sequential_model()\n",
    "# model1 = Sequential()\n",
    "# model1.add(Dense(1000, activation='relu', kernel_initializer='he_normal', name=\"dense_1\", input_shape=(data.n_features,)))\n",
    "# # model.add(Dense(10, activation='relu', kernel_initializer='he_normal', name=\"dense_2\"))\n",
    "# # model.add(Dense(300, activation='relu', kernel_initializer='he_normal', name=\"dense_3\"))\n",
    "# # model.add(Dense(200, activation='relu', kernel_initializer='he_normal', name=\"dense_4\"))\n",
    "\n",
    "# # model.add(Dense(n_classes, activation=\"softmax\", name=\"output\"))\n",
    "# model.add(Dense(1, activation=\"sigmoid\", name=\"output\"))\n",
    "\n",
    "# data._model = model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
